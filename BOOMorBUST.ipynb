{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from newsapi import NewsApiClient\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news api for collecting data\n",
    "api_key = os.getenv(\"news_api\")\n",
    "newsapi = NewsApiClient(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Price Performance (4 Weeks)</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Market Capitalization</th>\n",
       "      <th>Binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RHHBF</td>\n",
       "      <td>Roche Holding AG</td>\n",
       "      <td>-5.28026</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>$2.39T</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>-8.40659</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$2.09T</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com Inc</td>\n",
       "      <td>-5.98070</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>$1.55T</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRK/B</td>\n",
       "      <td>Berkshire Hathaway Inc</td>\n",
       "      <td>5.01114</td>\n",
       "      <td>Financials</td>\n",
       "      <td>$589.66B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V</td>\n",
       "      <td>Visa Inc</td>\n",
       "      <td>6.33930</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>$477.13B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JPM</td>\n",
       "      <td>JPMorgan Chase &amp; Co</td>\n",
       "      <td>9.99646</td>\n",
       "      <td>Financials</td>\n",
       "      <td>$473.79B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol            Company Name  Price Performance (4 Weeks)  \\\n",
       "0  RHHBF        Roche Holding AG                     -5.28026   \n",
       "1   AAPL               Apple Inc                     -8.40659   \n",
       "2   AMZN          Amazon.com Inc                     -5.98070   \n",
       "3  BRK/B  Berkshire Hathaway Inc                      5.01114   \n",
       "4      V                Visa Inc                      6.33930   \n",
       "5    JPM     JPMorgan Chase & Co                      9.99646   \n",
       "\n",
       "                   Sector Market Capitalization  Binary  \n",
       "0             Health Care                $2.39T       1  \n",
       "1  Information Technology                $2.09T       1  \n",
       "2  Consumer Discretionary                $1.55T       1  \n",
       "3              Financials              $589.66B       0  \n",
       "4  Information Technology              $477.13B       0  \n",
       "5              Financials              $473.79B       0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import our initial batch of 20 companies (10 bankrupt, 10 healthy)\n",
    "filepath = Path(\"../Project_2/Stocks_MasterList_Test.csv\")\n",
    "stocks_df = pd.read_csv(filepath, parse_dates=True, infer_datetime_format=True)\n",
    "stocks_df.head(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Company Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RHHBF</td>\n",
       "      <td>Roche Holding AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>Amazon.com Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRK/B</td>\n",
       "      <td>Berkshire Hathaway Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V</td>\n",
       "      <td>Visa Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>JPM</td>\n",
       "      <td>JPMorgan Chase &amp; Co</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Symbol            Company Name\n",
       "0  RHHBF        Roche Holding AG\n",
       "1   AAPL               Apple Inc\n",
       "2   AMZN          Amazon.com Inc\n",
       "3  BRK/B  Berkshire Hathaway Inc\n",
       "4      V                Visa Inc\n",
       "5    JPM     JPMorgan Chase & Co"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_info_df = stocks_df[['Symbol', 'Company Name']].copy()\n",
    "company_info_df.head(41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RHHBF AND Roche Holding AG', 'AAPL AND Apple Inc', 'AMZN AND Amazon.com Inc', 'BRK/B AND Berkshire Hathaway Inc', 'V AND Visa Inc', 'JPM AND JPMorgan Chase & Co']\n"
     ]
    }
   ],
   "source": [
    "search_list = []\n",
    "\n",
    "for index, row in company_info_df.iterrows():\n",
    "    ticker = row['Symbol']\n",
    "    company_name = row['Company Name']\n",
    "    search_string = ticker + ' ' + \"AND\" + ' ' + company_name\n",
    "    search_list.append(search_string)\n",
    "\n",
    "print(search_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['date', 'text', 'compound', 'positive', 'negative', 'neutral'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-f2ebdbf6b1e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0msentiment_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompany_sentiments\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# \"company_sentiments\" is the list from above\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"date\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"text\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compound\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"positive\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"negative\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"neutral\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0msentiment_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentiment_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0msentiment_stats_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentiment_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2804\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2805\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2806\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m         self._validate_read_indexer(\n\u001b[1;32m-> 1553\u001b[1;33m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1554\u001b[0m         )\n\u001b[0;32m   1555\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1638\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1639\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1640\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1642\u001b[0m             \u001b[1;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['date', 'text', 'compound', 'positive', 'negative', 'neutral'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# this is not finished!!!\n",
    "\n",
    "# we handled some of the data manipulation above, so the below funciton could be simplified\n",
    "\n",
    "company_sentiments = []\n",
    "\n",
    "for search_string in search_list:\n",
    "    company_headlines = newsapi.get_everything(\n",
    "        q = search_string, # here the function should iterate through each string in the list\n",
    "        language = \"en\", # english\n",
    "        page_size = 100, # not sure need to look at documentation\n",
    "        sort_by = \"relevancy\") # outside of relevance I thnk we should look at limiting # of articles and date range\n",
    "    \n",
    "    # now that we gathered the articles for the first company in the list in \"company_headlines\" we need to conduct the vader sentiment\n",
    "    for article in company_headlines[\"articles\"]:\n",
    "        try: \n",
    "            text = article[\"content\"]\n",
    "            date = article[\"publishedAt\"][:10] # the has impact on timing of articles, need to look a documentation\n",
    "            sentiment = analyzer.polarity_scores(text)\n",
    "            compound = sentiment[\"compound\"]\n",
    "            pos = sentiment[\"pos\"]\n",
    "            neu = sentiment[\"neu\"]\n",
    "            neg = sentiment[\"neg\"]\n",
    "        \n",
    "            company_sentiments.append({\n",
    "                \"text\": text,\n",
    "                \"date\": date,\n",
    "                \"compound\": compound,\n",
    "                \"positive\": pos,\n",
    "                \"negative\": neg,\n",
    "                \"neutral\": neu})\n",
    "        except AttributeError:\n",
    "            pass\n",
    "            \n",
    "    # now that we ran the vader analysis, we need to grab the describe dataframe\n",
    "    sentiment_df = pd.DataFrame(company_sentiments) # \"company_sentiments\" is the list from above\n",
    "    cols = [\"date\", \"text\", \"compound\", \"positive\", \"negative\", \"neutral\"]\n",
    "    sentiment_df = sentiment_df[cols]\n",
    "    sentiment_stats_df = sentiment_df.describe()\n",
    "    \n",
    "    ### update: I realized we do not need to append our sentiments directly to above dataframes, instead\n",
    "    # it is probaby easier just to create a new dataframe here then concat later\n",
    "    \n",
    "    # now need to append the outcomes to a dataframe - this can be new dataframe we later conccat to our original DF\n",
    "    final_sentiment_df = pd.DataFrame()\n",
    "    final_sentiment_df[\"compound\"] = sentiment_stats_df.at[1,'compound']\n",
    "    final_sentiment_df[\"positive\"] = sentiment_stats_df.at[1,'positive']\n",
    "    final_sentiment_df[\"negative\"] = sentiment_stats_df.at[1,'negative']\n",
    "    final_sentiment_df[\"neutral\"] = sentiment_stats_df.at[1,'neutral']\n",
    "    \n",
    "print(final_sentiment_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
